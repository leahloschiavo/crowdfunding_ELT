{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the crowdfunding.xlsx Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf_id</th>\n",
       "      <th>contact_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>blurb</th>\n",
       "      <th>goal</th>\n",
       "      <th>pledged</th>\n",
       "      <th>outcome</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>deadline</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>category &amp; sub-category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>4661</td>\n",
       "      <td>Baldwin, Riley and Jackson</td>\n",
       "      <td>Pre-emptive tertiary standardization</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>CAD</td>\n",
       "      <td>1581573600</td>\n",
       "      <td>1614578400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>food/food trucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1621</td>\n",
       "      <td>3765</td>\n",
       "      <td>Odom Inc</td>\n",
       "      <td>Managed bottom-line architecture</td>\n",
       "      <td>1400</td>\n",
       "      <td>14560</td>\n",
       "      <td>successful</td>\n",
       "      <td>158</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>1611554400</td>\n",
       "      <td>1621918800</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>music/rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812</td>\n",
       "      <td>4187</td>\n",
       "      <td>Melton, Robinson and Fritz</td>\n",
       "      <td>Function-based leadingedge pricing structure</td>\n",
       "      <td>108400</td>\n",
       "      <td>142523</td>\n",
       "      <td>successful</td>\n",
       "      <td>1425</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUD</td>\n",
       "      <td>1608184800</td>\n",
       "      <td>1640844000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>technology/web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2156</td>\n",
       "      <td>4941</td>\n",
       "      <td>Mcdonald, Gonzalez and Ross</td>\n",
       "      <td>Vision-oriented fresh-thinking conglomeration</td>\n",
       "      <td>4200</td>\n",
       "      <td>2477</td>\n",
       "      <td>failed</td>\n",
       "      <td>24</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>1634792400</td>\n",
       "      <td>1642399200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>music/rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1365</td>\n",
       "      <td>2199</td>\n",
       "      <td>Larson-Little</td>\n",
       "      <td>Proactive foreground core</td>\n",
       "      <td>7600</td>\n",
       "      <td>5265</td>\n",
       "      <td>failed</td>\n",
       "      <td>53</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>1608530400</td>\n",
       "      <td>1629694800</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>theater/plays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cf_id  contact_id                 company_name  \\\n",
       "0    147        4661   Baldwin, Riley and Jackson   \n",
       "1   1621        3765                     Odom Inc   \n",
       "2   1812        4187   Melton, Robinson and Fritz   \n",
       "3   2156        4941  Mcdonald, Gonzalez and Ross   \n",
       "4   1365        2199                Larson-Little   \n",
       "\n",
       "                                           blurb    goal  pledged     outcome  \\\n",
       "0           Pre-emptive tertiary standardization     100        0      failed   \n",
       "1               Managed bottom-line architecture    1400    14560  successful   \n",
       "2   Function-based leadingedge pricing structure  108400   142523  successful   \n",
       "3  Vision-oriented fresh-thinking conglomeration    4200     2477      failed   \n",
       "4                      Proactive foreground core    7600     5265      failed   \n",
       "\n",
       "   backers_count country currency  launched_at    deadline  staff_pick  \\\n",
       "0              0      CA      CAD   1581573600  1614578400       False   \n",
       "1            158      US      USD   1611554400  1621918800       False   \n",
       "2           1425      AU      AUD   1608184800  1640844000       False   \n",
       "3             24      US      USD   1634792400  1642399200       False   \n",
       "4             53      US      USD   1608530400  1629694800       False   \n",
       "\n",
       "   spotlight category & sub-category  \n",
       "0      False        food/food trucks  \n",
       "1       True              music/rock  \n",
       "2      False          technology/web  \n",
       "3      False              music/rock  \n",
       "4      False           theater/plays  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "crowdfunding_info_df = pd.read_excel('Resources/crowdfunding.xlsx')\n",
    "crowdfunding_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.get of      cf_id  contact_id                  company_name  \\\n",
       "0      147        4661    Baldwin, Riley and Jackson   \n",
       "1     1621        3765                      Odom Inc   \n",
       "2     1812        4187    Melton, Robinson and Fritz   \n",
       "3     2156        4941   Mcdonald, Gonzalez and Ross   \n",
       "4     1365        2199                 Larson-Little   \n",
       "..     ...         ...                           ...   \n",
       "995   2986        3684              Manning-Hamilton   \n",
       "996   2031        5784                    Butler LLC   \n",
       "997   1627        1498                      Ball LLC   \n",
       "998   2175        6073   Taylor, Santiago and Flores   \n",
       "999   1788        4939  Hernandez, Norton and Kelley   \n",
       "\n",
       "                                             blurb    goal  pledged  \\\n",
       "0             Pre-emptive tertiary standardization     100        0   \n",
       "1                 Managed bottom-line architecture    1400    14560   \n",
       "2     Function-based leadingedge pricing structure  108400   142523   \n",
       "3    Vision-oriented fresh-thinking conglomeration    4200     2477   \n",
       "4                        Proactive foreground core    7600     5265   \n",
       "..                                             ...     ...      ...   \n",
       "995            Vision-oriented scalable definition   97300   153216   \n",
       "996       Future-proofed upward-trending migration    6600     4814   \n",
       "997              Right-sized full-range throughput    7600     4603   \n",
       "998           Polarized composite customer loyalty   66600    37823   \n",
       "999                    Expanded eco-centric policy  111100    62819   \n",
       "\n",
       "        outcome  backers_count country currency  launched_at    deadline  \\\n",
       "0        failed              0      CA      CAD   1581573600  1614578400   \n",
       "1    successful            158      US      USD   1611554400  1621918800   \n",
       "2    successful           1425      AU      AUD   1608184800  1640844000   \n",
       "3        failed             24      US      USD   1634792400  1642399200   \n",
       "4        failed             53      US      USD   1608530400  1629694800   \n",
       "..          ...            ...     ...      ...          ...         ...   \n",
       "995  successful           2043      US      USD   1609221600  1622350800   \n",
       "996      failed            112      US      USD   1634274000  1638252000   \n",
       "997    canceled            139      IT      EUR   1636174800  1639116000   \n",
       "998      failed            374      US      USD   1602133200  1618117200   \n",
       "999    canceled           1122      US      USD   1609308000  1629262800   \n",
       "\n",
       "     staff_pick  spotlight category & sub-category  \n",
       "0         False      False        food/food trucks  \n",
       "1         False       True              music/rock  \n",
       "2         False      False          technology/web  \n",
       "3         False      False              music/rock  \n",
       "4         False      False           theater/plays  \n",
       "..          ...        ...                     ...  \n",
       "995       False       True        food/food trucks  \n",
       "996       False      False           theater/plays  \n",
       "997       False      False           theater/plays  \n",
       "998       False       True        music/indie rock  \n",
       "999       False      False        food/food trucks  \n",
       "\n",
       "[1000 rows x 15 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "crowdfunding_info_df.get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Category and Subcategory DataFrames\n",
    "---\n",
    "**Create a Category DataFrame that has the following columns:**\n",
    "- A \"category_id\" column that is numbered sequential form 1 to the length of the number of unique categories.\n",
    "- A \"category\" column that has only the categories.\n",
    "\n",
    "Export the DataFrame as a `category.csv` CSV file.\n",
    "\n",
    "**Create a SubCategory DataFrame that has the following columns:**\n",
    "- A \"subcategory_id\" column that is numbered sequential form 1 to the length of the number of unique subcategories.\n",
    "- A \"subcategory\" column that has only the subcategories. \n",
    "\n",
    "Export the DataFrame as a `subcategory.csv` CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'category_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'category_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Replace it with the actual name of your DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create Category DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m category_id \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: crowdfunding_info_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()})\n\u001b[0;32m      5\u001b[0m category_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(category_df) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Export Category DataFrame to category.csv\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'category_id'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace it with the actual name of your DataFrame\n",
    "\n",
    "# Create Category DataFrame\n",
    "category_id = pd.DataFrame({'category': crowdfunding_info_df['category_id'].unique()})\n",
    "category_df['category_id'] = range(1, len(category_df) + 1)\n",
    "\n",
    "# Export Category DataFrame to category.csv\n",
    "category_df.to_csv('category.csv', index=False)\n",
    "\n",
    "# Create SubCategory DataFrame\n",
    "scat_df = pd.DataFrame({'subcategory': crowdfunding_info_df['subcategory'].unique()})\n",
    "subcategory_df['subcategory_id'] = range(1, len(subcategory_df) + 1)\n",
    "\n",
    "# Export SubCategory DataFrame to subcategory.csv\n",
    "subcategory_df.to_csv('subcategory.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the category and subcategory values to category and subcategory columns.\n",
    "# Assuming crowdfunding_info_df is your DataFrame\n",
    "# Replace it with the actual name of your DataFrame\n",
    "\n",
    "# Create Category DataFrame\n",
    "category_df = pd.DataFrame({'category_id': crowdfunding_info_df['category_subcategory'].unique()})\n",
    "category_df['category_id'] = range(1, len(category_df) + 1)\n",
    "\n",
    "# Merge Category DataFrame to original DataFrame\n",
    "crowdfunding_info_df = pd.merge(crowdfunding_info_df, category_df, left_on='category_subcategory', right_on='category', how='left')\n",
    "crowdfunding_info_df.drop('category', axis=1, inplace=True)\n",
    "\n",
    "# Create SubCategory DataFrame\n",
    "subcategory_df = pd.DataFrame({'subcategory_id': crowdfunding_info_df['subcategory'].unique()})\n",
    "subcategory_df['subcategory_id'] = range(1, len(subcategory_df) + 1)\n",
    "\n",
    "# Merge SubCategory DataFrame to original DataFrame\n",
    "crowdfunding_info_df = pd.merge(crowdfunding_info_df, subcategory_df, left_on='subcategory', right_on='subcategory', how='left')\n",
    "crowdfunding_info_df.drop('subcategory', axis=1, inplace=True)\n",
    "\n",
    "# Export the updated DataFrame to a CSV file\n",
    "crowdfunding_info_df.to_csv('crowdfunding_info_updated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique categories and subcategories in separate lists.\n",
    "\n",
    "\n",
    "print(categories)\n",
    "print(subcategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of distinct values in the categories and subcategories lists.\n",
    "print(len(categories))\n",
    "print(len(subcategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays from 1-9 for the categories and 1-24 for the subcategories.\n",
    "\n",
    "\n",
    "\n",
    "category_ids = np.arange(1, 10)\n",
    "subcategory_ids = np.arange(1, 25)\n",
    "\n",
    "print(category_ids)\n",
    "print(subcategory_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to add \"cat\" to each category_id. \n",
    "\n",
    "# Use a list comprehension to add \"subcat\" to each subcategory_id.    \n",
    "\n",
    "# Add \"cat\" to each category_id\n",
    "category_df['cat_id'] = ['cat' + str(cat_id) for cat_id in category_df['category_id']]\n",
    "\n",
    "# Add \"subcat\" to each subcategory_id\n",
    "subcategory_df['scat_id'] = ['subcat' + str(subcat_id) for subcat_id in subcategory_df['subcategory_id']]\n",
    " \n",
    "print(cat_ids)\n",
    "print(scat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming category_df and subcategory_df are your DataFrames\n",
    "# Replace them with the actual names of your DataFrames\n",
    "\n",
    "# Add \"cat\" to each category_id\n",
    "category_df['cat_id'] = ['cat' + str(cat_id) for cat_id in category_df['category_id']]\n",
    "\n",
    "# Add \"subcat\" to each subcategory_id\n",
    "subcategory_df['scat_id'] = ['subcat' + str(subcat_id) for subcat_id in subcategory_df['subcategory_id']]\n",
    "\n",
    "# Print the modified columns\n",
    "print(category_df['cat_id'].tolist())\n",
    "print(subcategory_df['scat_id'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a category DataFrame with the category_id array as the category_id and categories list as the category name.\n",
    "\n",
    "# Create a category DataFrame with the subcategory_id array as the subcategory_id and subcategories list as the subcategory name. \n",
    "import pandas as pd\n",
    "\n",
    "# Example arrays (replace them with your actual data)\n",
    "category_id = [1, 2, 3]\n",
    "categories = ['CategoryA', 'CategoryB', 'CategoryC']\n",
    "\n",
    "subcategory_id = [1, 2, 3]\n",
    "subcategories = ['SubcategoryX', 'SubcategoryY', 'SubcategoryZ']\n",
    "\n",
    "# Create a Category DataFrame\n",
    "category_df = pd.DataFrame({'category_id': category_id, 'category': categories})\n",
    "\n",
    "# Create a SubCategory DataFrame\n",
    "subcategory_df = pd.DataFrame({'subcategory_id': subcategory_id, 'subcategory': subcategories})\n",
    "\n",
    "# Print the resulting DataFrames\n",
    "print(\"Category DataFrame:\")\n",
    "print(category_df)\n",
    "\n",
    "print(\"\\nSubCategory DataFrame:\")\n",
    "print(subcategory_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export categories_df and subcategories_df as CSV files.\n",
    "category_df.to_csv(\"Resources/category.csv\", index=False)\n",
    "\n",
    "subcategory_df.to_csv(\"Resources/subcategory.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign DataFrame\n",
    "----\n",
    "**Create a Campaign DataFrame that has the following columns:**\n",
    "- The \"cf_id\" column.\n",
    "- The \"contact_id\" column.\n",
    "- The “company_name” column.\n",
    "- The \"blurb\" column is renamed as \"description.\"\n",
    "- The \"goal\" column.\n",
    "- The \"goal\" column is converted to a `float` datatype.\n",
    "- The \"pledged\" column is converted to a `float` datatype. \n",
    "- The \"backers_count\" column. \n",
    "- The \"country\" column.\n",
    "- The \"currency\" column.\n",
    "- The \"launched_at\" column is renamed as \"launch_date\" and converted to a datetime format. \n",
    "- The \"deadline\" column is renamed as \"end_date\" and converted to a datetime format.\n",
    "- The \"category_id\" with the unique number matching the “category_id” from the category DataFrame. \n",
    "- The \"subcategory_id\" with the unique number matching the “subcategory_id” from the subcategory DataFrame.\n",
    "- And, create a column that contains the unique four-digit contact ID number from the `contact.xlsx` file.\n",
    " \n",
    "\n",
    "Then export the DataFrame as a `campaign.csv` CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the crowdfunding_info_df DataFrame name campaign_df. \n",
    "campaign_df = crowdfunding_info_df.copy()\n",
    "campaign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the blurb, launched_at, and deadline columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the goal and pledged columns to a `float` data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the launched_date and end_date columns to datetime format\n",
    "from datetime import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge the campaign_df with the category_df on the \"category\" column and \n",
    "# the subcategory_df on the \"subcategory\" column.\n",
    "\n",
    "\n",
    "campaign_merged_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "campaign_cleaned.to_csv(\"Resources/campaign.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the contacts.xlsx Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a Pandas DataFrame. Use the `header=2` parameter when reading in the data.\n",
    "contact_info_df = pd.read_excel('Resources/contacts.xlsx', header=2)\n",
    "contact_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Contacts DataFrame \n",
    "---\n",
    "**Create a Contacts DataFrame that has the following columns:**\n",
    "- A column named \"contact_id\"  that contains the unique number of the contact person.\n",
    "- A column named \"first_name\" that contains the first name of the contact person.\n",
    "- A column named \"last_name\" that contains the first name of the contact person.\n",
    "- A column named \"email\" that contains the email address of the contact person\n",
    "\n",
    "Then export the DataFrame as a `contacts.csv` CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use Pandas to create the contacts DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the contact_info_df and convert each row to a dictionary.\n",
    "import json\n",
    "dict_values = []\n",
    "\n",
    "\n",
    "# Print out the list of values for each row.\n",
    "print(dict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contact_info DataFrame and add each list of values, i.e., each row \n",
    "# to the 'contact_id', 'name', 'email' columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"first\"name\" and \"last_name\" column with the first and last names from the \"name\" column. \n",
    "\n",
    "\n",
    "# Drop the contact_name column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes one more time before exporting as CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "contacts_df_clean.to_csv(\"Resources/contacts.csv\", encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Use regex to create the contacts DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_info_df_copy = contact_info_df.copy()\n",
    "contact_info_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the four-digit contact ID number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"contact_id\" column to an int64 data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of the contact and add it to a new column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the email from the contacts and add the values to a new column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the contact_info_df with the 'contact_id', 'name', 'email' columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"first\"name\" and \"last_name\" column with the first and last names from the \"name\" column. \n",
    "\n",
    "\n",
    "# Drop the contact_name column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes one more time before exporting as CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "# contacts_df_clean.to_csv(\"Resources/contacts.csv\", encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
